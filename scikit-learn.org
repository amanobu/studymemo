- 
- 42:データのクリーニング
  - Nan・異常値の取り扱い
    - 取り除くか、工夫して値を埋める必要がある
  - ~np.isnan(X[:,0]) #1列目
    - arrayでTrue,Falseが帰ってくる
  - X1 = X[~np.isnan(X[:,0]) & ~np.isnan(X[:,1])]
    - 1と2行目のNanを削除しX1
  - X2 = X1[(abs(X1[:,0]) < 10) & (abs(X1[:,1]) < 10)]
    - 異常値を削除してX2
  - Nanを削除する代わりに平均値で埋める
    - sklearn.preprocessiong import Imputer
    - obj = Imputer()
    - obj.fit(...) #まず学習してあと
    - Xnew = obj.transfrom(X)
      - これでNanが平均値で埋まる。
    - 中央値も出来る(Imputer(strategy='median'))
- 43:テキストの特徴量抽出
  - 固定次元のベクトルに変更しなければならない
    - 解析が出来ない為
  - 特徴量の抽出の仕方はいっぱいある。
  - 一例でここではsklearnにある物でやってみる
- 44:画像の特徴量抽出
  - sklearnにあるものはわかりにくいので簡単に手でやってみる
  - ヒストグラムを作る
    - RGBのヒストグラムを別々に作って
  - それを組み合わせる
  - 画像によって大きさが変わるのでこの場合だと、ピクセル数で割ってどんな大きさでも同じ出力になるようにする
  - ただ、このままのデータでは使い物にならないので使わない

- 89:SVM
  - 線形のでスコアを試して後、非線形のスコアを試すのがおすすめ
  - フィーチャースケーリングしないと計算が終わらないこともあるので注意
  - 非線形カーネルのでデフォルトはrbfというのが使われるらしい
  - 非線形カーネルはパラメータの設定が難しいとのこと
- 90:多層パーセプトロン
  - デフォルトのパラメータではあんまり使い物のならない
- 91:層を変えてみる
- 92:癌データの認識
  - 無暗に層を増やしても性能は出ない
  - 根気よく？やるしかない。。。とのこと
- 93:ランダムフォレスト：2次元データの識別
  - clf.n_estimators = 木の数
    - 決定木1つと同じ
    - 増やすごとに識別するものが増える
  - clf.depth = 層の数
    - 木の層を何個にするか
- 94:
  - Treeの数が増えればオーバーフィット気味になる
- 95:癌データの識別
  - ランダムフォレストはスケーリングしてもあまり変わらない
    - 識別境界は条件によってきっちり分けられるので
- 96:ロジスティック回帰のパラメータ調整
  - Cのパラメータが重要
  - パラメータ調整するときによく使うのがGridSearchCVというオブジェクト
    - 格子上の点のところを点を探索していく
      - 別に多重次元でも問題ない
    - パラメータはDic型で指定
  - 大胆に変えていったほうがいい
    - 10倍ずつとか
  - デフォルトではクロスバリデーションのスコアが出る
    - gs.best_score_
  - g.best_estimator_にはすでに一番いい識別器がセットされている
  - Cが大きすぎると過学習になる
    - 計算量が増える

